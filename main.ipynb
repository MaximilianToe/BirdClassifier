{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "\n",
    "from modules.image_import_module import ImageDataset, get_subdirectories\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from modules.conformer import Conformer\n",
    "\n",
    "# Check if cuda is available and set random seed for reproducibility\n",
    "cuda = torch.cuda.is_available()  \n",
    "torch.manual_seed(0)\n",
    "if cuda:\n",
    "    print('cuda is available')\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "else:\n",
    "    print('cuda is not available')\n",
    "device = torch.device('cuda' if cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training data. \n",
    "- Combining the training data from all the subdirectories into one big dataset. \n",
    "- Randomize and create dataloaders for train, dev and test.\n",
    "\n",
    "Note that the training data (black-and-white spectrograms) are not included in this repository due to the file size (16GB). It can be downloaded on https://www.kaggle.com/datasets/forbo7/spectrograms-birdclef-2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!Due to the size, the dataset if not included in the repository and should be downloaded from the following link: https://www.kaggle.com/datasets/forbo7/spectrograms-birdclef-2023\n",
    "list_of_subdirectories = get_subdirectories('/spectrograms-birdclef-2023')\n",
    "idx_to_name = {}\n",
    "name_to_idx = {}\n",
    "\n",
    "for i, path in enumerate(list_of_subdirectories):\n",
    "    idx_to_name[i] = path.split('/')[-1]\n",
    "    name_to_idx[path.split('/')[-1]] = i\n",
    "\n",
    "list_of_datasets = []\n",
    "\n",
    "# optional: load the idx_to_name and name_to_idx dictionaries from a json file\n",
    "# with open('name_to_idx.json', 'r') as f:\n",
    "#     name_to_idx =json.load(f)\n",
    "\n",
    "# with open('idx_to_name.json', 'r') as f:\n",
    "#     idx_to_name = json.load(f)\n",
    "\n",
    "for i, path in enumerate(list_of_subdirectories):\n",
    "    current_dataset = ImageDataset(name_to_idx, path)\n",
    "    list_of_datasets.append(current_dataset)\n",
    "    \n",
    "complete_dataset = ConcatDataset(list_of_datasets)\n",
    "\n",
    "# Splitting the dataset into training and development sets\n",
    "train_size = int(0.90 * len(complete_dataset))\n",
    "dev_size = int(0.05*len(complete_dataset)) \n",
    "test_size = len(complete_dataset)-train_size -dev_size\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = random_split(complete_dataset, [train_size, dev_size, test_size])\n",
    "\n",
    "# Creating the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating the model.\n",
    "Currently the parameters are set to match the dimensions of the input spectrogram images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_classifier = Conformer(num_classes=264,input_channels=1,input_height=512, input_length=512, conv_kernel_size=31, num_heads=2, num_conformer_blocks=6,  subsampling_factor=2, device=device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying hyperparameters, loss and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10 \n",
    "learning_rate = 0.001\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bird_classifier.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "- Prints out the average loss and accuracy on the training data every epoch.\n",
    "- Saves the model every 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(1,epochs+1):\n",
    "    print(f\"current epoch {t}\")\n",
    "    array_of_losses = np.array([]) \n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    for data, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = bird_classifier(data)\n",
    "        predict = torch.argmax(output, dim=-1)\n",
    "        num_correct += torch.sum(labels==predict)\n",
    "        num_total += len(predict)\n",
    "        loss_val = loss(output, labels)\n",
    "        loss_val.backward()\n",
    "\n",
    "        optimizer.step() \n",
    "        array_of_losses = np.append(array_of_losses, loss_val.item())\n",
    "    \n",
    "    print(f\"accuracy on training data in epoch {t} is {num_correct/num_total}\")\n",
    "    print(f\"average loss is {np.mean(array_of_losses)}\")\n",
    "    if t%5 == 0 and t>0:\n",
    "        torch.save(bird_classifier.state_dict(), 'results/bird_classifier_epoch_' + str(t) + '.pth')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous model if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bird_classifier.load_state_dict(torch.load('bird_classifier_epoch_10.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model on the dev set to evaluate its performance and make changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_classifier.to('cpu')\n",
    "bird_classifier.eval()\n",
    "num_total = 0\n",
    "num_correct =0\n",
    "with torch.no_grad():\n",
    "    for data, labels in dev_loader:\n",
    "        yhat = bird_classifier(data)\n",
    "        pred = torch.argmax(yhat, dim =-1)\n",
    "        num_correct +=torch.sum(pred==labels)\n",
    "        num_total +=len(labels)\n",
    "   \n",
    "print(f\" accuracy is {num_correct/num_total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
